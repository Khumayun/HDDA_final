{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khumayun/HDDA_final/blob/master/result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAwyKu1TgIz-"
      },
      "source": [
        "## Final\n",
        "In this assignment you have difficult case when number of samples not bigger than number of dimensions. Here you should build classifier using train dataset, while test dataset is hidden. You can use any classifier from sklearn and transform features in any way too.\n",
        "\n",
        "Grading:\n",
        " - accuracy < 0.3 - no more than 5 pts\n",
        " - accuracy <= 0.35 - no more than 10 pts\n",
        " - accuracy <= 0.4 - no more than 15 pts\n",
        " - TOP 10 results - 30 points (maximum), others weighted amount of points between 30 and 20 points for those who get more than 0.40 according to difference between their score and worst score of TOP 10\n",
        " - accuracy >= 0.5 - at least 25 pts\n",
        " - accuracy >= 0.6 - at least 30 pts\n",
        " "
      ],
      "id": "SAwyKu1TgIz-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoR8-PpngI0B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "id": "RoR8-PpngI0B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuVoGGh1gI0C",
        "outputId": "b5bd8a73-0a64-4b93-f092-a7e3ec521c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3072, 3072), (3072,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X = np.loadtxt('X_train')\n",
        "y = np.loadtxt('y_train', dtype=np.int)\n",
        "\n",
        "X.shape, y.shape"
      ],
      "id": "UuVoGGh1gI0C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BznyFG_4gI0D"
      },
      "source": [
        "### Train part\n",
        "- implement feature transformation procedure in the function `transform_X(X)` if it is nedeed\n",
        "- you can use any classifier, just try to find good hyperparameters, name your result classifier `clf`\n",
        "- on the submition should be only 1 classifier in other case i can choose worst one\n",
        "\n",
        "don't forget about danger of overfitting to train data\n",
        "\n",
        "HERE baseline solution with SVM and with feature transformation that doesn't change anything"
      ],
      "id": "BznyFG_4gI0D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvjDSFZAgI0D"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing"
      ],
      "id": "TvjDSFZAgI0D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6YcLwEHgI0E"
      },
      "outputs": [],
      "source": [
        "def transform_X(X, y):\n",
        "    ## YOUR CODE FOR FEATURE TRANSFORMATION HERE\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.4, random_state=0)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "id": "g6YcLwEHgI0E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEW03EA5gI0F"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = transform_X(X, y)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)"
      ],
      "id": "WEW03EA5gI0F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "212BkR3tgI0F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "id": "212BkR3tgI0F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBDuD5NZgI0G"
      },
      "outputs": [],
      "source": [
        "## I WANT TO MAKE A SYNTHETIC DATA BASED ON GIVEN, FOR TRAIN AND VALIDATION PURPOSES"
      ],
      "id": "fBDuD5NZgI0G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2KeQF7qgI0G"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "id": "j2KeQF7qgI0G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWKNOh4egI0H"
      },
      "outputs": [],
      "source": [
        "X_train = np.loadtxt('X_train')\n",
        "y_train = np.loadtxt('y_train')\n",
        "data = pd.DataFrame(data=X_train, columns=[x for x in range(3072)])\n",
        "data['outcome'] = y_train"
      ],
      "id": "fWKNOh4egI0H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeF6u-xBgI0H"
      },
      "outputs": [],
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = generator.predict(x_input)\n",
        "    y = np.zeros((n_samples, 1))\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "# generate n real samples with class labels; We randomly select n samples from the real data\n",
        "def generate_real_samples(n):\n",
        "    X = data.sample(n)\n",
        "    y = np.ones((n, 1))\n",
        "    return X, y\n",
        "\n",
        "def define_generator(latent_dim, n_outputs=10):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(15, activation='relu',  kernel_initializer='he_uniform', input_dim=latent_dim))\n",
        "    model.add(Dense(30, activation='relu'))\n",
        "    model.add(Dense(n_outputs, activation='linear'))\n",
        "    return model"
      ],
      "id": "VeF6u-xBgI0H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpBWzW1VgI0I"
      },
      "outputs": [],
      "source": [
        "def define_discriminator(n_inputs=10):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "id": "rpBWzW1VgI0I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZKkcmb8gI0I"
      },
      "outputs": [],
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(generator, discriminator):\n",
        "    # make weights in the discriminator not trainable\n",
        "    discriminator.trainable = False\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(generator)\n",
        "    # add the discriminator\n",
        "    model.add(discriminator)\n",
        "    # compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return model"
      ],
      "id": "wZKkcmb8gI0I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o7BVWfagI0J"
      },
      "outputs": [],
      "source": [
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d_hist, g_hist):\n",
        "    # plot loss\n",
        "    plt.subplot(1, 1, 1)\n",
        "    plt.plot(d_hist, label='d')\n",
        "    plt.plot(g_hist, label='gen')\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "id": "1o7BVWfagI0J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpHSGq0egI0J"
      },
      "outputs": [],
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=1000, n_batch=128, n_eval=200):\n",
        "  # determine half the size of one batch, for updating the  discriminator\n",
        "  half_batch = int(n_batch / 2)\n",
        "  d_history = []\n",
        "  g_history = []\n",
        "  # manually enumerate epochs\n",
        "  for epoch in range(n_epochs):\n",
        "    # prepare real samples\n",
        "    x_real, y_real = generate_real_samples(half_batch)\n",
        "    # prepare fake examples\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "    # update discriminator\n",
        "    d_loss_real, d_real_acc = d_model.train_on_batch(x_real, y_real)\n",
        "    d_loss_fake, d_fake_acc = d_model.train_on_batch(x_fake, y_fake)\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "    # prepare points in latent space as input for the generator\n",
        "    x_gan = generate_latent_points(latent_dim, n_batch)\n",
        "    # create inverted labels for the fake samples\n",
        "    y_gan = np.ones((n_batch, 1))\n",
        "    # update the generator via the discriminator's error\n",
        "    g_loss_fake = gan_model.train_on_batch(x_gan, y_gan)\n",
        "    #         print('>%d, d1=%.3f, d2=%.3f d=%.3f g=%.3f' % (epoch+1, d_loss_real, d_loss_fake, d_loss,  g_loss_fake))\n",
        "    d_history.append(d_loss)\n",
        "    g_history.append(g_loss_fake)\n",
        "    #     g_model.save('trained_generated_model.h5')\n",
        "  plot_history(d_history, g_history)\n",
        "  return g_model"
      ],
      "id": "IpHSGq0egI0J"
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import randn\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pKl17_Nahtoh"
      },
      "id": "pKl17_Nahtoh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "jUAe35HKgI0K",
        "outputId": "9a652a1c-310f-4dc7-b825-a6a252cedf53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# size of the latent space\n",
        "latent_dim = 3073\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator(3073)\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim, 3073)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# # train model\n",
        "model = train(generator, discriminator, gan_model, latent_dim)"
      ],
      "id": "jUAe35HKgI0K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elc8A67vgI0K"
      },
      "outputs": [],
      "source": [
        "latent_points = generate_latent_points(3073, 750)\n",
        "X_faked = model.predict(latent_points)"
      ],
      "id": "Elc8A67vgI0K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1BVbL-tgI0L"
      },
      "outputs": [],
      "source": [
        "data_fake = pd.DataFrame(data=X_faked,  columns=[x for x in range(3072)]+['outcome'])\n",
        "data_fake['outcome'] = data_fake['outcome'].astype(int)\n",
        "y = data_fake['outcome']"
      ],
      "id": "F1BVbL-tgI0L"
    },
    {
      "cell_type": "code",
      "source": [
        "data_fake.drop('outcome', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "1lPs1VD9ivjn"
      },
      "id": "1lPs1VD9ivjn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZGu2Ah4gI0L"
      },
      "outputs": [],
      "source": [
        "from numpy.random import randn\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "YZGu2Ah4gI0L"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = transform_X(data_fake, y)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)"
      ],
      "metadata": {
        "id": "rCcZZS3uis-8"
      },
      "id": "rCcZZS3uis-8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-W7W9uAgI0M",
        "outputId": "364dcd12-739d-4a7d-9d06-64dee022a337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "## compare multiple classifiers\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=1),\n",
        "    SVC(gamma=2, C=1),\n",
        "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    MLPClassifier(alpha=1, max_iter=1000),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "# COMPARE CLASSIFIERS\n",
        "accuracies = []\n",
        "scoring = ['precision_macro']\n",
        "for clf in classifiers:\n",
        "    # clf.fit(X_train_transformed, y_train)\n",
        "    scores = cross_validate(clf, X_train_transformed, y_train, scoring=scoring)\n",
        "    accuracies.append(np.max(list(scores['test_precision_macro'])))\n",
        "#     clf_y_pred = clf.predict(X_test)\n",
        "#     accuracies.append(accuracy_score(y_test, clf_y_pred))\n",
        "\n",
        "# SELECT BEST CLASSIFIER\n",
        "clf = classifiers[np.argmax(accuracies)]\n",
        "clf"
      ],
      "id": "j-W7W9uAgI0M"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE0kNWt0jG0Q",
        "outputId": "8fbcb6e3-a431-449c-89eb-4e24443094a2"
      },
      "id": "CE0kNWt0jG0Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.961111111111111,\n",
              " 0.9916666666666668,\n",
              " 0.10222222222222221,\n",
              " 0.4023529411764706,\n",
              " 0.9877551020408163,\n",
              " 0.9747965589397815,\n",
              " 0.9393939393939394,\n",
              " 0.9957446808510639,\n",
              " 0.9136067997043608,\n",
              " 0.10337078651685394]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTdnarsxgI0M"
      },
      "source": [
        "### Test part, don't change anything here\n",
        "\n",
        "Here is used your `clf` trained before, at your folder **Test** and **Train** datasets are the same, but during grading differen **Test** dataset will be used"
      ],
      "id": "iTdnarsxgI0M"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4GBMIxVgI0N"
      },
      "outputs": [],
      "source": [
        "X_test = np.loadtxt('X_test')\n",
        "y_test = np.loadtxt('y_test', dtype=np.int)"
      ],
      "id": "H4GBMIxVgI0N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNQ_-38OgI0N"
      },
      "outputs": [],
      "source": [
        "y_pred = clf.predict(transform_X(X_test))\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "id": "zNQ_-38OgI0N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cKSa3StgI0N"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "1cKSa3StgI0N"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "result.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}